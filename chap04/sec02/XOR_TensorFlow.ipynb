{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. 訓練データと正解ラベルの用意\n",
    "'''\n",
    "import numpy as np\n",
    "\n",
    "train = np.array([[0, 0],  # 0と1の組み合わせの行列(4データ,2列)              \n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "label = np.array([[0],     # 正解ラベル(4データ,1列)\n",
    "                  [1],\n",
    "                  [1],\n",
    "                  [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. モデルの定義\n",
    "'''\n",
    "import tensorflow as tf\n",
    "\n",
    "class MLP(tf.keras.Model):\n",
    "    '''多層パーセプトロン\n",
    "    \n",
    "    Attributes:\n",
    "      l1(Dense): 隠れ層\n",
    "      l2(Dense): 出力層\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        '''モデルの初期化を行う\n",
    "        \n",
    "        Parameters:\n",
    "          input_dim: 入力する1データあたりの値の形状\n",
    "          hidden_dim(int): 隠れ層のニューロン数\n",
    "          output_dim(int): 出力層のニューロン数\n",
    "        '''\n",
    "        super(MLP, self).__init__() # スーパークラスの__init__()を実行\n",
    "        # 隠れ層\n",
    "        self.l1 = tf.keras.layers.Dense(\n",
    "            units=hidden_dim,     # ニューロンのサイズ\n",
    "            input_dim=input_dim,  # 入力データの形状\n",
    "            activation='sigmoid') # 活性化関数はシグモイド\n",
    "        # 出力層\n",
    "        self.l2 = tf.keras.layers.Dense(\n",
    "            units=output_dim,     # ニューロンのサイズ\n",
    "            activation='sigmoid') # 活性化関数はシグモイド\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x, training=None):\n",
    "        '''モデルのインスタンスからコールバックされる関数\n",
    "        \n",
    "        MLPの順伝播処理を行う\n",
    "        \n",
    "        Parameters:\n",
    "          x(ndarray(float32)): 訓練データ、または検証データ\n",
    "          training(bool): 訓練True、検証False\n",
    "        Returns(float32): 出力層からの出力値    \n",
    "        '''\n",
    "        h = self.l1(x) # 隠れ層の出力\n",
    "        y = self.l2(h) # 出力層の出力\n",
    "        return y\n",
    "\n",
    "# 入力層2ニューロン、隠れ層2ニューロン、出力層1ニューロンのモデルを生成\n",
    "model = MLP(2, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3. 損失関数とオプティマイザーの生成\n",
    "'''\n",
    "# バイナリ用のクロスエントロピー誤差のオブジェクトを生成\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "# 勾配降下アルゴリズムを使用するオプティマイザーを生成\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "4. 勾配降下アルゴリズムによるパラメーターの更新処理\n",
    "'''\n",
    "@tf.function\n",
    "def train_step(x, t):\n",
    "    '''バックプロパゲーションによるパラメーター更新を行う\n",
    "    \n",
    "    Parameters: x(ndarray(float32)):訓練データ\n",
    "                t(ndarray(float32)):正解ラベル\n",
    "                \n",
    "    Returns:\n",
    "      MLPの出力と正解ラベルのクロスエントロピー誤差\n",
    "    '''\n",
    "    # 自動微分による勾配計算のための操作を記録するブロック\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x) # モデルに入力して順伝搬の出力値を取得\n",
    "        pred_loss = loss_fn(t, predictions) # 出力値と正解ラベルの誤差を取得\n",
    "        \n",
    "    # tapeに記録された操作を使用して誤差の勾配を計算        \n",
    "    gradients = tape.gradient(       \n",
    "        pred_loss, # 現在の誤差       \n",
    "        model.trainable_variables) # 更新可能なバイアス、重みのリストを取得\n",
    "    \n",
    "    # 勾配降下法の更新式を適用してバイアス、重みを更新\n",
    "    optimizer.apply_gradients(\n",
    "        zip(gradients, # 取得済みの勾配\n",
    "            model.trainable_variables # 更新可能なバイアス、重みのリスト\n",
    "           ))\n",
    "    return pred_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(1000) loss: 0.0594\n",
      "epoch(2000) loss: 0.0151\n",
      "epoch(3000) loss: 0.0085\n",
      "epoch(4000) loss: 0.0058\n",
      "Model: \"mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  6         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  3         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "5. モデルを使用して学習する\n",
    "'''\n",
    "# エポック数\n",
    "epochs = 4000                           \n",
    "\n",
    "# 学習を行う\n",
    "for epoch in range(epochs):\n",
    "    # 1エポックごとの損失を保持する変数\n",
    "    epoch_loss = 0.\n",
    "    \n",
    "    # データをモデルに入力し、バイアス、重みを更新して誤差を取得\n",
    "    loss = train_step(train, label)        \n",
    "    epoch_loss += loss.numpy()\n",
    "\n",
    "    # 10000エポックごとに結果を出力\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print('epoch({}) loss: {:.4f}'.format(epoch+1, epoch_loss))\n",
    "\n",
    "# モデルの構造を出力\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.00685593]\n",
      " [0.9947802 ]\n",
      " [0.99473214]\n",
      " [0.00595838]], shape=(4, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]], shape=(4, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "6. モデルを評価する\n",
    "'''\n",
    "# 学習済みのMLPの出力\n",
    "print(model(train))\n",
    "\n",
    "# 学習した重み・バイアスを使ってXORゲートの出力を表示\n",
    "# MLPの出力が0.5以上であれば1、そうでなければ0を返す\n",
    "print(tf.cast(((model(train)) >= 0.5), tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
