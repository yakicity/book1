{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class neuralNetwork:\n",
    "    '''ニューラルネットワークを生成する\n",
    "    \n",
    "    Attributes:\n",
    "      input(int)(int) : 入力層のニューロン数\n",
    "      fc1(int): 隠れ層のニューロン数\n",
    "      fc2(int): 出力層のニューロン数\n",
    "      lr(float): 学習率\n",
    "      w1(array): 隠れ層のバイアス、重み行列\n",
    "      w2(array): 出力層のバイアス、重み行列\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, learning_rate):\n",
    "        '''ニューラルネットワークの初期化を行う\n",
    "        \n",
    "        Parameters:\n",
    "          input_dim(int) : 入力層のニューロン数\n",
    "          hidden_dim(int): 隠れ層のニューロン数\n",
    "          output_dim(int): 出力層のニューロン数\n",
    "          learning_rate(float): 学習率\n",
    "\n",
    "        '''\n",
    "        # 入力層、隠れ層、出力層のニューロン数をインスタンス変数に代入\n",
    "        self.input = input_dim    # 入力層のニューロン数\n",
    "        self.fc1 = hidden_dim     # 隠れ層のニューロン数\n",
    "        self.fc2 = output_dim     # 出力層のニューロン数\n",
    "        self.lr = learning_rate   # 学習率\n",
    "        self.weight_initializer() # weight_initializer()を呼ぶ\n",
    "\n",
    "    def weight_initializer(self):\n",
    "        '''重みとバイアスの初期化を行う\n",
    "        \n",
    "        '''\n",
    "        # 隠れ層の重みとバイアス\n",
    "        # (隠れ層のニューロン数\n",
    "        self.w1 = np.random.normal(\n",
    "            0.0,                   # 平均は0\n",
    "            pow(self.input, -0.5), # 標準偏差は入力層のデータサイズを元に計算\n",
    "            (self.fc1,             # 行数は隠れ層のニューロン数\n",
    "             self.input + 1)       # 列数は入力層のデータサイズ + 1\n",
    "            )\n",
    "        \n",
    "       # 出力層の重みとバイアスを初期化\n",
    "        self.w2 = np.random.normal(\n",
    "            0.0,                 # 平均は0\n",
    "            pow(self.fc1, -0.5), # 標準偏差は隠れ層のニューロン数を元に計算\n",
    "            (self.fc2,           # 行数は出力層のニューロン数\n",
    "             self.fc1 + 1)       # 列数は隠れ層のニューロン数 + 1\n",
    "            )\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        '''シグモイド関数\n",
    "        \n",
    "        Parameters:\n",
    "          x(array): 関数を適用するデータ\n",
    "        '''\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def softmax(self, x):\n",
    "        '''ソフトマックス関数\n",
    "        \n",
    "        Parameters:\n",
    "          x(array): 関数を適用するデータ\n",
    "        '''\n",
    "        c = np.max(x)\n",
    "        exp_x = np.exp(x - c) # オーバーフロー対策\n",
    "        sum_exp_x = np.sum(exp_x)\n",
    "        y = exp_x / sum_exp_x\n",
    "        return y\n",
    "    \n",
    "    def train(self, train_x, train_y):\n",
    "        '''ニューラルネットワークの学習を行う\n",
    "        \n",
    "        Parameters：\n",
    "          train_x(array): 訓練データ\n",
    "          train_y(array): 正解ラベル\n",
    "        '''\n",
    "        ## [入力層]\n",
    "        # 入力値の配列にバイアス項を追加して入力層から出力する\n",
    "        inputs = np.array(\n",
    "            np.append(train_x, [1]), # 配列の末尾にバイアスのための「1」を追加\n",
    "            ndmin=2                  # 2次元化\n",
    "            ).T                      # 転置して1列の行列にする\n",
    "\n",
    "        ## [隠れ層]\n",
    "        # 入力層の出力に重み、バイアスを適用して隠れ層に入力する\n",
    "        hidden_inputs = np.dot(\n",
    "            self.w1, # 隠れ層の重み\n",
    "            inputs   # 入力層の出力\n",
    "            )\n",
    "        # シグモイド関数を適用して隠れ層から出力\n",
    "        hidden_outputs = self.sigmoid(hidden_inputs)      \n",
    "        # 隠れ層の出力行列の末尾にバイアスのための「1」を追加\n",
    "        hidden_outputs = np.append(\n",
    "            hidden_outputs, # 隠れ層の出力行列\n",
    "            [[1]],          # 2次元形式でバイアス値を追加\n",
    "            axis=0          # 行を指定(列は1)\n",
    "            )\n",
    "        \n",
    "        ## [出力層]\n",
    "        # 出力層への入力信号を作る\n",
    "        final_inputs = np.dot(\n",
    "            self.w2,       # 隠れ層と出力層の間の重み\n",
    "            hidden_outputs # 隠れ層の出力\n",
    "            )\n",
    "        # ソフトマックス関数を適用して出力層から出力する\n",
    "        final_outputs = self.softmax(final_inputs)\n",
    "\n",
    "        ## ---バックプロパゲーション---(出力層)\n",
    "        # 正解ラベルの配列を1列の行列に変換する\n",
    "        targets = np.array(\n",
    "            train_y,        # 正解ラベルの配列\n",
    "            ndmin=2              # 2次元化\n",
    "            ).T                  # 転置して1列の行列にする\n",
    "        # 出力値と正解ラベルとの誤差\n",
    "        output_errors = final_outputs - targets\n",
    "        # 出力層の入力誤差δを求める\n",
    "        delta_output = output_errors*(1 - final_outputs)*final_outputs\n",
    "        # 重みを更新する前に隠れ層の出力誤差を求めておく\n",
    "        hidden_errors = np.dot(\n",
    "            self.w2.T,           # 出力層の重み行列を転置する\n",
    "            delta_output         # 出力層の入力誤差δ\n",
    "            )\n",
    "        # 出力層の重み、バイアスの更新\n",
    "        self.w2 -= self.lr * np.dot(\n",
    "            # 出力誤差＊(1－出力信号)＊出力信号 \n",
    "            delta_output,\n",
    "            # 隠れ層の出力行列を転置\n",
    "            hidden_outputs.T\n",
    "        )\n",
    "\n",
    "        ## ---バックプロパゲーション---(隠れ層)\n",
    "        # 逆伝搬された隠れ層の出力誤差からバイアスのものを取り除く\n",
    "        hidden_errors_nobias = np.delete(\n",
    "            hidden_errors,  # 隠れ層のエラーの行列\n",
    "            self.fc1, # 隠れ層のニューロン数をインデックスにして末尾要素を削除\n",
    "            axis=0    # 行の削除を指定\n",
    "            )\n",
    "        # 隠れ層の出力行列からバイアスを除く\n",
    "        hidden_outputs_nobias = np.delete(\n",
    "            hidden_outputs, # 隠れ層の出力の行列\n",
    "            self.fc1, # 隠れ層のニューロン数をインデックスにして末尾要素を削除\n",
    "            axis=0    # 行の削除を指定\n",
    "            )\n",
    "        # 隠れ層の重み、バイアスの更新\n",
    "        self.w1 -= self.lr * np.dot(\n",
    "            # 逆伝搬された隠れ層の出力誤差＊(1－隠れ層の出力)＊隠れ層の出力 \n",
    "            hidden_errors_nobias*(\n",
    "                1.0 - hidden_outputs_nobias\n",
    "            )*hidden_outputs_nobias,\n",
    "            # 入力層の出力信号の行列を転置\n",
    "            inputs.T\n",
    "            )\n",
    "        \n",
    "    def evaluate(self, inputs_list):\n",
    "        '''学習した重みでテストデータを評価する\n",
    "        \n",
    "        Parameters:\n",
    "          inputs_list(array): テスト用データ\n",
    "        Returns:\n",
    "          array: モデルからの出力\n",
    "        '''\n",
    "        ## [入力層]\n",
    "        # 入力値の配列にバイアス項を追加して入力層から出力する\n",
    "        inputs = np.array(\n",
    "            np.append(inputs_list, [1]), # 配列の末尾にバイアスの「1」を追加\n",
    "            ndmin=2                      # 2次元化\n",
    "        ).T                              # 転置して1列の行列にする\n",
    "        \n",
    "        ## [隠れ層]\n",
    "        # 入力層の出力に重み、バイアスを適用して隠れ層に入力する\n",
    "        hidden_inputs = np.dot(self.w1,  # 入力層と隠れ層の間の重み\n",
    "                               inputs    # テストデータの行列\n",
    "                              )       \n",
    "        # 活性化関数を適用して隠れ層から出力する\n",
    "        hidden_outputs = self.sigmoid(hidden_inputs)\n",
    "        \n",
    "        ## [出力層]\n",
    "        # 出力層への入力信号を計算\n",
    "        final_inputs = np.dot(\n",
    "            self.w2,                        # 隠れ層と出力層の間の重み\n",
    "            np.append(hidden_outputs, [1]), # 隠れ層の出力配列の末尾にバイアスの「1」を追加\n",
    "            )       \n",
    "        # 活性化関数を適用して出力層から出力する\n",
    "        final_outputs = self.softmax(final_inputs)\n",
    "        \n",
    "        # 出力層からの出力を戻り値として返す\n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
